# Landmark Model Input/Output Logging

This feature allows you to log the input images and output landmarks from the landmark detection model to analyze jitter and stability.

## How to Use

1. **Start the app** and navigate to the camera view
2. **Position your face** in front of the camera (keep still if testing stability)
3. **Click the "ðŸ“Š Log Landmark I/O (3s)" button** in the bottom sheet
4. The button will change to "ðŸ“Š Logging... (3s)" and become disabled
5. After 3 seconds, logging will automatically stop
6. A toast message will show the file location where logs were saved

## Where Files Are Saved

Logs are saved to:
```
/storage/emulated/0/Android/data/org.tensorflow.lite.examples.gaze_estimation/files/landmark_logs/session_YYYYMMDD_HHMMSS/
```

Each session contains:
- `left_eye/` - Directory with PNG images of left eye crops (60x60 RGB)
  - Files named: `left_eye_frame_0001.png`, `left_eye_frame_0002.png`, etc.
- `right_eye/` - Directory with PNG images of right eye crops (60x60 RGB)
  - Files named: `right_eye_frame_0001.png`, `right_eye_frame_0002.png`, etc.
- `face/` - Directory with PNG images of face crops (120x120 RGB)
  - Files named: `face_frame_0001.png`, `face_frame_0002.png`, etc.
- `landmark_outputs.csv` - CSV file with all landmark outputs
  - Columns: `frame`, `timestamp_ms`, `landmark_0`, `landmark_1`, ..., `landmark_135`
- `jitter_analysis.png` - (Generated by analysis script) Visualization of jitter

## Accessing the Files

### Using ADB:
```bash
# List all logging sessions
adb shell ls -la /storage/emulated/0/Android/data/org.tensorflow.lite.examples.gaze_estimation/files/landmark_logs/

# Pull a specific session
adb pull /storage/emulated/0/Android/data/org.tensorflow.lite.examples.gaze_estimation/files/landmark_logs/session_20250101_120000 ./landmark_logs/
```

### Using File Manager:
Navigate to: `Internal Storage > Android > data > org.tensorflow.lite.examples.gaze_estimation > files > landmark_logs`

## Analyzing Jitter

### Using the Python Analysis Script

1. **Install dependencies:**
   ```bash
   pip install numpy pillow matplotlib
   ```

2. **Pull the log files from device:**
   ```bash
   adb pull /storage/emulated/0/Android/data/org.tensorflow.lite.examples.gaze_estimation/files/landmark_logs ./landmark_logs
   ```

3. **Run the analysis script:**
   ```bash
   python analyze_landmark_jitter.py ./landmark_logs/session_20250101_120000
   ```

The script will:
- Analyze gaze model input stability for left eye, right eye, and face crops
- Analyze landmark output jitter (how much landmarks change)
- Generate a visualization plot (`jitter_analysis.png`)
- Print summary statistics for each region

### What to Look For

**Gaze Model Input Stability (Left Eye, Right Eye, Face):**
- **Mean frame difference < 5.0**: Input is stable (good)
- **Mean frame difference > 10.0**: Input is unstable (may cause jitter)
- These are the actual inputs to the gaze estimation model, so their stability directly affects gaze jitter

**Landmark Jitter:**
- **Overall std dev < 1.0**: Low jitter (good)
- **Overall std dev > 2.0**: High jitter (needs more smoothing)

**Frame-to-frame differences:**
- Should be relatively constant if face is still
- Large spikes indicate sudden changes (may be detection errors)
- Compare left eye vs right eye - if one is more stable, it may indicate head pose issues

### Manual Analysis

You can also manually inspect the files:

1. **View gaze model input images:**
   - Open the PNG files in `left_eye/`, `right_eye/`, and `face/` directories
   - Check if images are stable (should look nearly identical if face is still)
   - Compare left eye vs right eye - they should be similarly stable
   - The face crop should be the most stable since it's larger

2. **Analyze CSV:**
   - Open `landmark_outputs.csv` in Excel or a text editor
   - Look at specific landmark coordinates across frames
   - Calculate variance: `=VAR.S(column_range)` in Excel
   - Higher variance = more jitter

3. **Compare frames:**
   - Use image diff tools to compare consecutive input frames
   - Should show minimal differences if face is still

## Troubleshooting

**Button doesn't work:**
- Make sure a face is detected (bounding box visible)
- Check logcat for errors: `adb logcat | grep LandmarkLogging`

**No files saved:**
- Check app permissions (should have storage permission)
- Check available storage space
- Look for errors in logcat

**Analysis script fails:**
- Make sure all files are present (input_images/ and landmark_outputs.csv)
- Check Python dependencies are installed
- Verify the path to log directory is correct

## Example Output

```
Loading gaze model inputs...
Loaded 90 left eye images
Loaded 90 right eye images
Loaded 90 face images

Analyzing input stability...

Left Eye:
  Mean pixel variance: 2.34
  Max pixel variance: 15.67
  Mean frame difference: 3.21
  Max frame difference: 8.45

Right Eye:
  Mean pixel variance: 2.18
  Max pixel variance: 14.23
  Mean frame difference: 3.05
  Max frame difference: 7.89

Face:
  Mean pixel variance: 1.95
  Max pixel variance: 12.45
  Mean frame difference: 2.78
  Max frame difference: 6.34

Loading landmark outputs...
Loaded 90 landmark outputs
Analyzing landmark jitter...
  Overall std dev: 0.45
  Max std dev: 2.13
  Mean frame difference: 0.32
  Max frame difference: 1.87

Generating plots...

=== Summary ===
LEFT_EYE Stability: STABLE (mean diff: 3.21)
RIGHT_EYE Stability: STABLE (mean diff: 3.05)
FACE Stability: STABLE (mean diff: 2.78)
Landmark Jitter: LOW

Full analysis saved to: ./landmark_logs/session_20250101_120000
```

